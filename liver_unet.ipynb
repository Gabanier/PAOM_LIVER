{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Liver & Tumor Segmentation - Cascaded U-Net\n",
    "\n",
    "This notebook implements a two-stage cascaded approach for liver and tumor segmentation from CT scans using the Medical Segmentation Decathlon Task03_Liver dataset.\n",
    "\n",
    "**Architecture:**\n",
    "1. Stage 1: Liver segmentation U-Net\n",
    "2. Stage 2: Tumor segmentation U-Net (conditioned on liver mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS (consolidated - no duplicates)\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from monai.data import CacheDataset, Dataset, DataLoader, decollate_batch # type: ignore\n",
    "from monai.inferers import sliding_window_inference # type: ignore\n",
    "from monai.losses import DiceCELoss # type: ignore\n",
    "from monai.metrics import DiceMetric # type: ignore\n",
    "from monai.networks.nets import UNet # type: ignore\n",
    "from monai.transforms import ( \n",
    "    AsDiscrete, # type: ignore\n",
    "    Compose, # type: ignore\n",
    "    CopyItemsd, # type: ignore\n",
    "    CropForegroundd, # type: ignore\n",
    "    EnsureChannelFirstd, # type: ignore\n",
    "    EnsureTyped, # type: ignore\n",
    "    Lambdad, # type: ignore\n",
    "    LoadImaged, # type: ignore\n",
    "    MaskIntensityd, # type: ignore\n",
    "    Orientationd, # type: ignore\n",
    "    RandCropByLabelClassesd, # type: ignore\n",
    "    RandFlipd, # type: ignore\n",
    "    RandRotate90d, # type: ignore\n",
    "    RandShiftIntensityd, # type: ignore\n",
    "    ScaleIntensityRanged, # type: ignore\n",
    "    Spacingd, # type: ignore\n",
    "    SpatialPadd, # type: ignore\n",
    ")\n",
    "from monai.utils import set_determinism # type: ignore\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "set_determinism(42)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "ROOT = Path(\"data/Task03_Liver\")\n",
    "IMAGES_TR = ROOT / \"imagesTr\"\n",
    "LABELS_TR = ROOT / \"labelsTr\"\n",
    "IMAGES_TS = ROOT / \"imagesTs\"\n",
    "\n",
    "# Model hyperparameters\n",
    "ROI_LIVER = (32, 32, 32)\n",
    "ROI_TUMOR = (64, 64, 32)\n",
    "PIXDIM = (1.5, 1.5, 2.0)\n",
    "HU_MIN, HU_MAX = -200, 200\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 4\n",
    "VAL_FRAC = 0.2\n",
    "SEED = 42\n",
    "CACHE_RATE = 0.1\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_EPOCHS = 200\n",
    "SW_BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loading & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA UTILITIES\n",
    "# =============================================================================\n",
    "def list_nii(folder: Path) -> list[Path]:\n",
    "    \"\"\"List all valid NIfTI files in a folder, excluding macOS hidden files.\"\"\"\n",
    "    return sorted(\n",
    "        p for p in folder.glob(\"*.nii.gz\")\n",
    "        if p.is_file() and not p.name.startswith(\"._\")\n",
    "    )\n",
    "\n",
    "\n",
    "def split_train_val(files: list, val_frac: float = 0.2, seed: int = 42) -> tuple[list, list]:\n",
    "    \"\"\"Split files into train and validation sets.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(files))\n",
    "    rng.shuffle(idx)\n",
    "    \n",
    "    n_val = int(len(files) * val_frac)\n",
    "    val_idx, tr_idx = idx[:n_val], idx[n_val:]\n",
    "    \n",
    "    return [files[i] for i in tr_idx], [files[i] for i in val_idx]\n",
    "\n",
    "\n",
    "# Build file lists\n",
    "train_imgs = list_nii(IMAGES_TR)\n",
    "test_imgs = list_nii(IMAGES_TS)\n",
    "\n",
    "train_files = [{\"image\": str(p), \"label\": str(LABELS_TR / p.name)} for p in train_imgs]\n",
    "test_files = [{\"image\": str(p)} for p in test_imgs]\n",
    "\n",
    "print(f\"Total: {len(train_files)} train+val, {len(test_files)} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transforms-header",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transforms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRANSFORM PIPELINES\n",
    "# =============================================================================\n",
    "\n",
    "def get_common_transforms(keys: list[str], include_label: bool = True) -> list:\n",
    "    \"\"\"Get common preprocessing transforms shared across all pipelines.\"\"\"\n",
    "    return [\n",
    "        LoadImaged(keys=keys),\n",
    "        EnsureChannelFirstd(keys=keys),\n",
    "        Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=keys,\n",
    "            pixdim=PIXDIM,\n",
    "            mode=(\"bilinear\", \"nearest\") if include_label else (\"bilinear\",)\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=HU_MIN, a_max=HU_MAX,\n",
    "            b_min=0.0, b_max=1.0,\n",
    "            clip=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_augmentation_transforms(keys: list[str]) -> list:\n",
    "    \"\"\"Get data augmentation transforms for training.\"\"\"\n",
    "    return [\n",
    "        RandFlipd(keys=keys, prob=0.5, spatial_axis=0),\n",
    "        RandFlipd(keys=keys, prob=0.5, spatial_axis=1),\n",
    "        RandFlipd(keys=keys, prob=0.5, spatial_axis=2),\n",
    "        RandRotate90d(keys=keys, prob=0.2, max_k=3),\n",
    "        RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.3),\n",
    "    ]\n",
    "\n",
    "\n",
    "# --- Liver Segmentation Transforms ---\n",
    "liver_train_tf = Compose([\n",
    "    *get_common_transforms([\"image\", \"label\"]),\n",
    "    Lambdad(keys=[\"label\"], func=lambda x: (x > 0).astype(x.dtype)),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=ROI_LIVER),\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=ROI_LIVER,\n",
    "        num_samples=4,\n",
    "        num_classes=2,\n",
    "        ratios=[0.2, 0.8],\n",
    "        warn=False,\n",
    "    ),\n",
    "    *get_augmentation_transforms([\"image\", \"label\"]),\n",
    "    EnsureTyped(keys=[\"image\", \"label\"], dtype=(torch.float32, torch.int64)),\n",
    "])\n",
    "\n",
    "liver_val_tf = Compose([\n",
    "    *get_common_transforms([\"image\", \"label\"]),\n",
    "    Lambdad(keys=[\"label\"], func=lambda x: (x > 0).astype(x.dtype)),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=ROI_LIVER),\n",
    "    EnsureTyped(keys=[\"image\", \"label\"], dtype=(torch.float32, torch.int64)),\n",
    "])\n",
    "\n",
    "liver_test_tf = Compose([\n",
    "    *get_common_transforms([\"image\"], include_label=False),\n",
    "    CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "    SpatialPadd(keys=[\"image\"], spatial_size=ROI_LIVER),\n",
    "    EnsureTyped(keys=[\"image\"], dtype=torch.float32),\n",
    "])\n",
    "\n",
    "\n",
    "# --- Tumor Segmentation Transforms ---\n",
    "tumor_train_tf = Compose([\n",
    "    *get_common_transforms([\"image\", \"label\"]),\n",
    "    CopyItemsd(keys=[\"label\"], times=1, names=[\"liver\"]),\n",
    "    Lambdad(keys=[\"liver\"], func=lambda x: (x > 0).astype(x.dtype)),\n",
    "    Lambdad(keys=[\"label\"], func=lambda x: (x == 2).astype(x.dtype)),\n",
    "    CropForegroundd(keys=[\"image\", \"label\", \"liver\"], source_key=\"liver\"),\n",
    "    MaskIntensityd(keys=[\"image\"], mask_key=\"liver\"),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=ROI_TUMOR),\n",
    "    RandCropByLabelClassesd(\n",
    "        keys=[\"image\", \"label\"],\n",
    "        label_key=\"label\",\n",
    "        spatial_size=ROI_TUMOR,\n",
    "        num_samples=6,\n",
    "        num_classes=2,\n",
    "        ratios=[0.3, 0.7],\n",
    "        warn=False,\n",
    "    ),\n",
    "    *get_augmentation_transforms([\"image\", \"label\"]),\n",
    "    EnsureTyped(keys=[\"image\", \"label\"], dtype=(torch.float32, torch.int64)),\n",
    "])\n",
    "\n",
    "tumor_val_tf = Compose([\n",
    "    *get_common_transforms([\"image\", \"label\"]),\n",
    "    CopyItemsd(keys=[\"label\"], times=1, names=[\"liver\"]),\n",
    "    Lambdad(keys=[\"liver\"], func=lambda x: (x > 0).astype(x.dtype)),\n",
    "    Lambdad(keys=[\"label\"], func=lambda x: (x == 2).astype(x.dtype)),\n",
    "    CropForegroundd(keys=[\"image\", \"label\", \"liver\"], source_key=\"liver\"),\n",
    "    MaskIntensityd(keys=[\"image\"], mask_key=\"liver\"),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=ROI_TUMOR),\n",
    "    EnsureTyped(keys=[\"image\", \"label\"], dtype=(torch.float32, torch.int64)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "datamodule-header",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "datamodules",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA MODULE\n",
    "# =============================================================================\n",
    "\n",
    "class SegmentationDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Unified data module for segmentation tasks.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_files: list,\n",
    "        train_tf,\n",
    "        val_tf,\n",
    "        test_files = None,\n",
    "        test_tf=None,\n",
    "        batch_size: int = 1,\n",
    "        num_workers: int = 4,\n",
    "        val_frac: float = 0.2,\n",
    "        seed: int = 42,\n",
    "        cache_rate_train: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_files = train_files\n",
    "        self.test_files = test_files or []\n",
    "        self.train_tf = train_tf\n",
    "        self.val_tf = val_tf\n",
    "        self.test_tf = test_tf\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_frac = val_frac\n",
    "        self.seed = seed\n",
    "        self.cache_rate_train = cache_rate_train\n",
    "        self.train_ds = None\n",
    "        self.val_ds = None\n",
    "        self.test_ds = None\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        tr_files, val_files = split_train_val(self.train_files, self.val_frac, self.seed)\n",
    "        \n",
    "        self.train_ds = CacheDataset(\n",
    "            tr_files,\n",
    "            transform=self.train_tf,\n",
    "            cache_rate=self.cache_rate_train,\n",
    "            num_workers=0,\n",
    "        )\n",
    "        self.val_ds = Dataset(val_files, transform=self.val_tf)\n",
    "        \n",
    "        if self.test_files and self.test_tf:\n",
    "            self.test_ds = Dataset(self.test_files, transform=self.test_tf)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds, batch_size=self.batch_size, shuffle=True,\n",
    "            num_workers=self.num_workers, pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds, batch_size=1, shuffle=False,\n",
    "            num_workers=max(0, self.num_workers // 2), pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.test_ds is None:\n",
    "            return None\n",
    "        return DataLoader(\n",
    "            self.test_ds, batch_size=1, shuffle=False,\n",
    "            num_workers=max(0, self.num_workers // 2), pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL ARCHITECTURE\n",
    "# =============================================================================\n",
    "\n",
    "def build_unet(\n",
    "    in_channels: int = 1,\n",
    "    out_channels: int = 2,\n",
    "    channels: tuple = (16, 32, 64, 128, 256),\n",
    "    strides: tuple = (2, 2, 2, 2),\n",
    ") -> UNet:\n",
    "    \"\"\"Build a 3D U-Net with instance normalization.\"\"\"\n",
    "    return UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        channels=channels,\n",
    "        strides=strides,\n",
    "        num_res_units=2,\n",
    "        norm=\"INSTANCE\",\n",
    "    )\n",
    "\n",
    "\n",
    "def build_unet_liver() -> UNet:\n",
    "    \"\"\"Build U-Net for liver segmentation (larger network).\"\"\"\n",
    "    return build_unet(channels=(16, 32, 64, 128, 256), strides=(2, 2, 2, 2))\n",
    "\n",
    "\n",
    "def build_unet_tumor(in_channels: int = 1) -> UNet:\n",
    "    \"\"\"Build U-Net for tumor segmentation (smaller network).\"\"\"\n",
    "    return build_unet(in_channels=in_channels, channels=(16, 32, 64, 128), strides=(2, 2, 2))\n",
    "\n",
    "\n",
    "class LiverTumorCascade(nn.Module):\n",
    "    \"\"\"Cascaded model: liver segmentation -> tumor segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        liver_net: nn.Module,\n",
    "        tumor_net: nn.Module,\n",
    "        mode: str = \"mask\",\n",
    "        liver_class_idx: int = 1,\n",
    "        threshold = None,\n",
    "        freeze_liver: bool = True,\n",
    "        detach_liver: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if mode not in (\"mask\", \"concat\"):\n",
    "            raise ValueError(f\"mode must be 'mask' or 'concat', got '{mode}'\")\n",
    "        \n",
    "        self.liver_net = liver_net\n",
    "        self.tumor_net = tumor_net\n",
    "        self.mode = mode\n",
    "        self.liver_class_idx = liver_class_idx\n",
    "        self.threshold = threshold\n",
    "        self.freeze_liver = freeze_liver\n",
    "        self.detach_liver = detach_liver\n",
    "        \n",
    "        if freeze_liver:\n",
    "            for param in self.liver_net.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        # Stage 1: Liver segmentation\n",
    "        if self.freeze_liver:\n",
    "            self.liver_net.eval()\n",
    "            with torch.no_grad():\n",
    "                liver_logits = self.liver_net(x)\n",
    "        else:\n",
    "            liver_logits = self.liver_net(x)\n",
    "        \n",
    "        liver_prob = F.softmax(liver_logits, dim=1)[:, self.liver_class_idx : self.liver_class_idx + 1]\n",
    "        \n",
    "        if self.threshold is not None:\n",
    "            liver_mask = (liver_prob > self.threshold).to(liver_prob.dtype)\n",
    "        else:\n",
    "            liver_mask = liver_prob\n",
    "        \n",
    "        if self.detach_liver:\n",
    "            liver_mask = liver_mask.detach()\n",
    "        \n",
    "        # Stage 2: Tumor segmentation\n",
    "        tumor_in = x * liver_mask if self.mode == \"mask\" else torch.cat([x, liver_mask], dim=1)\n",
    "        tumor_logits = self.tumor_net(tumor_in)\n",
    "        \n",
    "        return {\n",
    "            \"liver_logits\": liver_logits,\n",
    "            \"liver_mask\": liver_mask,\n",
    "            \"tumor_logits\": tumor_logits,\n",
    "            \"tumor_in\": tumor_in,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightning-header",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightning-modules",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PYTORCH LIGHTNING MODULES\n",
    "# =============================================================================\n",
    "\n",
    "class BaseSegmentationModule(pl.LightningModule):\n",
    "    \"\"\"Base Lightning module for segmentation tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, lr: float = 1e-4, roi_size: tuple = (64, 64, 32), sw_batch_size: int = 2, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"net\", \"cascade\"])\n",
    "        self.lr = lr\n",
    "        self.roi_size = roi_size\n",
    "        self.sw_batch_size = sw_batch_size\n",
    "        \n",
    "        self.loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "        self.post_pred = AsDiscrete(argmax=True, to_onehot=num_classes)\n",
    "        self.post_label = AsDiscrete(to_onehot=num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "class LiverSegmentationModule(BaseSegmentationModule):\n",
    "    \"\"\"Lightning module for liver-only segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, net: nn.Module, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.net(batch[\"image\"])\n",
    "        loss = self.loss_fn(logits, batch[\"label\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = sliding_window_inference(batch[\"image\"], self.roi_size, self.sw_batch_size, self.net)\n",
    "        preds = [self.post_pred(p) for p in decollate_batch(logits)]\n",
    "        labels = [self.post_label(l) for l in decollate_batch(batch[\"label\"])]\n",
    "        self.dice_metric(preds, labels)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val_dice_liver\", self.dice_metric.aggregate().item(), prog_bar=True)\n",
    "        self.dice_metric.reset()\n",
    "\n",
    "\n",
    "class TumorSegmentationModule(BaseSegmentationModule):\n",
    "    \"\"\"Lightning module for tumor-only segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, net: nn.Module, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.net(batch[\"image\"])\n",
    "        loss = self.loss_fn(logits, batch[\"label\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = sliding_window_inference(batch[\"image\"], self.roi_size, self.sw_batch_size, self.net)\n",
    "        preds = [self.post_pred(p) for p in decollate_batch(logits)]\n",
    "        labels = [self.post_label(l) for l in decollate_batch(batch[\"label\"])]\n",
    "        self.dice_metric(preds, labels)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        dice = self.dice_metric.aggregate()\n",
    "        self.log(\"val_dice_tumor\", dice.item() if dice.numel() == 1 else dice[0].item(), prog_bar=True)\n",
    "        self.dice_metric.reset()\n",
    "\n",
    "\n",
    "class CascadeSegmentationModule(BaseSegmentationModule):\n",
    "    \"\"\"Lightning module for cascaded liver->tumor segmentation.\"\"\"\n",
    "    \n",
    "    def __init__(self, cascade: LiverTumorCascade, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cascade = cascade\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cascade(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self.cascade(batch[\"image\"])\n",
    "        loss = self.loss_fn(out[\"tumor_logits\"], batch[\"label\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = sliding_window_inference(\n",
    "            batch[\"image\"], self.roi_size, self.sw_batch_size,\n",
    "            lambda x: self.cascade(x)[\"tumor_logits\"]\n",
    "        )\n",
    "        preds = [self.post_pred(p) for p in decollate_batch(logits)]\n",
    "        labels = [self.post_label(l) for l in decollate_batch(batch[\"label\"])]\n",
    "        self.dice_metric(preds, labels)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        dice = self.dice_metric.aggregate()\n",
    "        self.log(\"val_dice_tumor\", dice.item() if dice.numel() == 1 else dice[0].item(), prog_bar=True)\n",
    "        self.dice_metric.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.cascade.tumor_net.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAGE 1: LIVER SEGMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "liver_net = build_unet_liver()\n",
    "liver_module = LiverSegmentationModule(net=liver_net, lr=LEARNING_RATE, roi_size=ROI_LIVER, sw_batch_size=SW_BATCH_SIZE)\n",
    "\n",
    "liver_dm = SegmentationDataModule(\n",
    "    train_files=train_files, train_tf=liver_train_tf, val_tf=liver_val_tf,\n",
    "    test_files=test_files, test_tf=liver_test_tf,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, val_frac=VAL_FRAC, seed=SEED, cache_rate_train=CACHE_RATE,\n",
    ")\n",
    "\n",
    "liver_checkpoint = ModelCheckpoint(monitor=\"val_dice_liver\", mode=\"max\", save_top_k=1, filename=\"liver_segementation-{epoch:02d}-{val_dice_liver:.3f}\",)\n",
    "liver_cvs_logger = CSVLogger(save_dir=\"lightning_logs\", name=\"liver_segementation\")\n",
    "\n",
    "liver_trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=liver_cvs_logger,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    default_root_dir=\"lightning_logs\",\n",
    "    callbacks=[liver_checkpoint],\n",
    "    devices=1,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# Uncomment to train:\n",
    "liver_trainer.fit(liver_module, datamodule=liver_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAGE 2a: TUMOR SEGMENTATION (standalone with GT liver mask)\n",
    "# =============================================================================\n",
    "\n",
    "tumor_net = build_unet_tumor(in_channels=1)\n",
    "tumor_module = TumorSegmentationModule(net=tumor_net, lr=LEARNING_RATE, roi_size=ROI_TUMOR, sw_batch_size=SW_BATCH_SIZE)\n",
    "\n",
    "tumor_dm = SegmentationDataModule(\n",
    "    train_files=train_files, train_tf=tumor_train_tf, val_tf=tumor_val_tf,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, val_frac=VAL_FRAC, seed=SEED, cache_rate_train=CACHE_RATE,\n",
    ")\n",
    "\n",
    "tumor_checkpoint = ModelCheckpoint(monitor=\"val_dice_tumor\", mode=\"max\", save_top_k=1, filename=\"tumor_segementation-{epoch:02d}-{val_dice_tumor:.3f}\",)\n",
    "tumor_cvs_logger = CSVLogger(save_dir=\"lightning_logs\", name=\"tumor_segementation\")\n",
    "\n",
    "tumor_trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=tumor_cvs_logger,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    default_root_dir=\"lightning_logs\",\n",
    "    callbacks=[tumor_checkpoint],\n",
    "    devices=1,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# Uncomment to train:\n",
    "# tumor_trainer.fit(tumor_module, datamodule=tumor_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-cascade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STAGE 2b: CASCADED TUMOR SEGMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load pre-trained liver weights if available:\n",
    "# cascade_liver_net.load_state_dict(torch.load(\"liver_best.pth\"))\n",
    "\n",
    "cascade_liver_net = build_unet_liver()\n",
    "cascade_tumor_net = build_unet_tumor(in_channels=1)\n",
    "\n",
    "cascade_model = LiverTumorCascade(\n",
    "    liver_net=cascade_liver_net,\n",
    "    tumor_net=cascade_tumor_net,\n",
    "    mode=\"mask\",\n",
    "    threshold=None,\n",
    "    freeze_liver=True,\n",
    "    detach_liver=True,\n",
    ")\n",
    "\n",
    "cascade_module = CascadeSegmentationModule(cascade=cascade_model, lr=LEARNING_RATE, roi_size=ROI_TUMOR, sw_batch_size=SW_BATCH_SIZE)\n",
    "\n",
    "cascade_dm = SegmentationDataModule(\n",
    "    train_files=train_files, train_tf=tumor_train_tf, val_tf=tumor_val_tf,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, val_frac=VAL_FRAC, seed=SEED, cache_rate_train=CACHE_RATE,\n",
    ")\n",
    "\n",
    "cascade_checkpoint = ModelCheckpoint(monitor=\"val_dice_tumor\", mode=\"max\", save_top_k=1, filename=\"cascade_segementation-{epoch:02d}-{val_dice_tumor:.3f}\",)\n",
    "cascade_cvs_logger = CSVLogger(save_dir=\"lightning_logs\", name=\"cascade_segementation\")\n",
    "\n",
    "cascade_trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=cascade_cvs_logger,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    default_root_dir=\"lightning_logs\",\n",
    "    callbacks=[cascade_checkpoint],\n",
    "    devices=1,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# Uncomment to train:\n",
    "# cascade_trainer.fit(cascade_module, datamodule=cascade_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## Visualization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZATION\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "def show_slice(ax, sl_img, sl_msk=None, title=\"\"):\n",
    "    \"\"\"Display a single slice with optional mask overlay.\"\"\"\n",
    "    vmin, vmax = np.percentile(sl_img, [1, 99])\n",
    "    ax.imshow(np.rot90(sl_img), cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    if sl_msk is not None:\n",
    "        ax.imshow(np.rot90((sl_msk == 1).astype(np.uint8)), alpha=0.25, cmap=\"Blues\")\n",
    "        ax.imshow(np.rot90((sl_msk == 2).astype(np.uint8)), alpha=0.65, cmap=\"Reds\")\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def visualize_sample(img_path: Path, msk_path= None):\n",
    "    \"\"\"Visualize axial, coronal, and sagittal slices.\"\"\"\n",
    "    img = nib.load(str(img_path)).get_fdata()\n",
    "    msk = nib.load(str(msk_path)).get_fdata().astype(np.int32) if msk_path else None\n",
    "    \n",
    "    z, y, x = img.shape[2] // 2, img.shape[1] // 2, img.shape[0] // 2\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    show_slice(axs[0], img[:, :, z], msk[:, :, z] if msk is not None else None, f\"Axial z={z}\")\n",
    "    show_slice(axs[1], img[:, y, :], msk[:, y, :] if msk is not None else None, f\"Coronal y={y}\")\n",
    "    show_slice(axs[2], img[x, :, :], msk[x, :, :] if msk is not None else None, f\"Sagittal x={x}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example:\n",
    "visualize_sample(list_nii(IMAGES_TR)[1], LABELS_TR / list_nii(IMAGES_TR)[1].name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSN_PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
